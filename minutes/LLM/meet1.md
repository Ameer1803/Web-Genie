Minutes 15/05

Brief: An introductory meet discussing ML, AI and common terms describing the backbone of LLM's. 

Topics Covered:
- The crux of ML
- How other forms of input can be reduced to simple ML
- Vectorization 
- How GPT produces output tokens
- The inside of an LLM
- History of NLP Models
- Transformers and attention
- BERT and GPT 

To be done
- Complete week 0 resources.
- Secy task: Sec A task 1
- Learn about BERT Models
- Go through "Attention is all you need" paper if time

